input {
#  http {port => 8000}
  file {
    path => "/root/config/logstash-7.5.2/earthquakes.csv"
    # 文件作为输入源，有一个坏处，日志文件必须删除重建，因为logstash 文件读取的原因
    start_position => "beginning"
    # 每次可以重新开始
    sincedb_path => "/dev/null"
  }
}

filter {

    csv {
      # 指定字段名
      columns => ["time","latitude","longitude","depth","mag","magType","nst","gap","dmin","rms","net","id","updated","place","type","horizontalError","depthError","magError","magNst","status","locationSource","magSource"]
      # 指定类型
      convert => {"latitude"=>"float"}
      convert => {"longitude"=>"float"}
      convert => {"depth"=>"float"}
      convert => {"mag"=>"float"}
      convert => {"gap"=>"float"}
      convert => {"dmin "=>"float"}
      convert => {"rms"=>"float"}
    }

    mutate {
      # 符合 es 经纬度的字段
      add_field =>{ "location" =>"%{latitude},%{longitude}"}
      remove_field => ["latitude","longitude"]
    }

    date {
      #  2016/01/01 00:30:04.91
      match => [ "time","yyyy-MM-dd'T'HH:mm:ss.SSS Z"]
      # 删除 timestamp 字段
      remove_field => ["timestamp"]
    }
}

output {
  elasticsearch {
    hosts => ["http://127.0.0.1:9200"]
    index => "earthquake"
  }
}
