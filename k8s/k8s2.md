# ubuntu

修改ip 地址

```
vim /etc/netplan/50-cloud-init.yaml

network:
  version: 2
  ethernets:
    ens33:
      dhcp4: no
      addresses: [192.168.110.130/24]
      gateway4: 192.168.110.1
      nameservers:
        addresses: [8.8.8.8, 114.114.114.114]

sudo netplan apply
        
# 每次手动改 /etc/netplan/50-cloud-init.yaml 并运行 netplan apply 后虽然生效，但 重启后 Cloud-Init 会重新生成它，导致配置被还原。
sudo tee /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg > /dev/null <<EOF
network: {config: disabled}
EOF
```

如果是使用k8s基础镜像包，执行 1、2 直接跳到 4 初始化，文件位于 /opt/k8s-offline 目录。

    kubeadm init --config kubeadm.yaml --upload-certs -v=6

主节点执行 1、2、3、4、5

工作节点执行 1、2、3、7

# 步骤 1：准备系统

关闭交换分区

```shell
sudo swapoff -a
sudo sed -i '/ swap / s/^/#/' /etc/fstab

sudo systemctl disable ufw --now
```

加载必要的内核模块并设置系统参数：

```shell
sudo modprobe overlay
sudo modprobe br_netfilter

sudo tee /etc/sysctl.d/kubernetes.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
EOF

sudo sysctl --system
```

# 步骤 2：安装 containerd（推荐的容器运行时）

```shell
sudo apt update
sudo apt install -y containerd
```

配置 containerd：

```shell
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
```

编辑 /etc/containerd/config.toml，将 SystemdCgroup 设置为 true：

```shell
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true
  
# 修改对应的镜像版本 
sandbox_image = "registry.k8s.io/pause:3.8"  
```

然后重启 containerd：

```shell
sudo systemctl restart containerd
sudo systemctl enable containerd

```

# 步骤 3：安装 kubeadm、kubelet 和 kubectl

```shell

sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl

sudo curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.33/deb/Release.key | sudo gpg --dearmor -o /usr/share/keyrings/kubernetes-archive-keyring.gpg

echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt update

sudo apt install -y kubelet kubeadm kubectl
# 锁定版本以防止意外升级（可选）
sudo apt-mark hold kubelet kubeadm kubectl

sudo tee /etc/crictl.yaml > /dev/null <<EOF
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false
EOF

# 配置hostname
echo "192.168.110.123 master" >> /etc/hosts
echo "192.168.110.124 node1" >> /etc/hosts
echo "192.168.110.126 node2" >> /etc/hosts

systemctl daemon-reexec
systemctl enable kubelet
systemctl restart kubelet


sudo mkdir -p /opt/cni/bin

rm -rf /opt/cni/bin/*

sudo tar -xzvf /opt/k8s-offline/bin/cni-plugins-linux-amd64-v1.7.1.tgz -C /opt/cni/bin/

``` 

# 步骤 4：初始化主节点

主节点初始化镜像和网络插件镜像全部使用离线镜像

```shell
ctr -n k8s.io images ls



# 查看 k8s 需要的镜像版本
kubeadm config images list --kubernetes-version v1.33.1

cd /opt/k8s-offline/images

# 加载本地镜像包
for img in *.tar; do
    ctr -n k8s.io images import $img
done

cd ../

# debug 启动
kubeadm init --config kubeadm.yaml --upload-certs -v=6

echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bashrc
source ~/.bashrc

crictl ps -a

kubectl get nodes
```

初始化完成后，设置 kubectl 配置：

```shell
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

# 步骤 5：安装网络插件（以 Flannel 为例）

```shell
#kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
kubectl apply -f kube.flannel.yml
```

# 步骤 6：加入节点

在 master 上执行：

```shell
kubeadm token create --print-join-command
```

然后在每个 node 节点上执行输出的命令。

从节点执行

```shell
# 先关闭交换内存
sudo swapoff -a
sudo sed -i '/swap/ s/^/#/' /etc/fstab
# 输出应该是 空的，表示 swap 已关闭。
swapon --summary

# 设置改主机名称
sudo hostnamectl set-hostname node1

# 查看主机名称
hostname

# 如果端口又被占用的情况，执行 sh 中 clean.sh 脚本
kubeadm join k8s-master:6443 --token cizzvo.fbzp7mdqz1y8x3sg \
--discovery-token-ca-cert-hash sha256:3294a1f7b2387f2367d8db11de50db6623669390b3bf1707b260c17edcb244c7 \
--control-plane --certificate-key 10b0bf4b6278d031dfee19eb185c7f94cb473c710497204ab8e5f0304ff5acb0

# 加入成功如果想在从节点执行 kubectl 相关命令,在主节点执行该命令
scp /etc/kubernetes/admin.conf root@192.168.110.126:/root/.kube/config

# 从节点执行
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
# zsh
echo 'export KUBECONFIG=/root/.kube/config' >> ~/.zshrc
source ~/.zshrc
# bash
echo 'export KUBECONFIG=/root/.kube/config' >> ~/.bashrc
source ~/.bashrc

```

# 7 给工作节点打标签

```shell
kubectl label node node1 node-role.kubernetes.io/worker=worker
kubectl label node node2 node-role.kubernetes.io/worker=worker
```

![img.png](img.png)





# 注意事项

虚拟机重启后交换内存和规则会被重置，需要重新设置。
